{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Spam Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/maukanmir/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_imbalance(df:pd.DataFrame, target:pd.Series, col:str):\n",
    "  counter = Counter(target)\n",
    "  for k,v in counter.items():\n",
    "    per = v/len(target) * 100\n",
    "    print(\"Class=%s, Count=%d, Percentage=%.3f%%\" % (k,v, per))\n",
    "  df[col].value_counts().plot.bar()\n",
    "  \n",
    "def remove_stop_words(review:str):\n",
    "\n",
    "    word_tokens = \" \".join(word_tokenize(review))\n",
    "    filtered_word_tokens = re.sub(r'[^a-zA-Z\\s]', '', word_tokens).split(\" \")\n",
    "    \n",
    "    filtered_sentence = [w.lower().strip() for w in filtered_word_tokens if not w.lower() in ENGLISH_STOP_WORDS]\n",
    "    return ' '.join(filtered_sentence).strip()\n",
    "def evaluate_model(X, y, model):\n",
    "  # define evaluation procedure\n",
    "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(accuracy_score)\n",
    "  # evaluate model\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        # summarize and store\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>naturally irresistible your corporate identity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>the stock trading gunslinger fanny is merrill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>unbelievable new homes made easy im wanting to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>4 color printing special request additional in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>do not have money get software cds from here s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20343</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20344</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20345</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20346</th>\n",
       "      <td>ham</td>\n",
       "      <td>Kaisi hii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20347</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shock q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20348 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "0          spam  naturally irresistible your corporate identity...\n",
       "1          spam  the stock trading gunslinger fanny is merrill ...\n",
       "2          spam  unbelievable new homes made easy im wanting to...\n",
       "3          spam  4 color printing special request additional in...\n",
       "4          spam  do not have money get software cds from here s...\n",
       "...         ...                                                ...\n",
       "20343       ham                                               /ban\n",
       "20344       ham                                               /ban\n",
       "20345       ham                                               /ban\n",
       "20346       ham                                          Kaisi hii\n",
       "20347       ham                                            Shock q\n",
       "\n",
       "[20348 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/maukanmir/Downloads/dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check For Nulls & Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Null values: text_type    0\n",
      "text         0\n",
      "dtype: int64\n",
      "# Dupe values: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Null values: {df.isna().sum()}\")\n",
    "print(f\"# Dupe values: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20329</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM DETECTION  User:     Username: @DillyBubb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20330</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM DETECTION  User:     Username: @DillyBubb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20331</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM DETECTION  User:     Username: @DillyBubb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20332</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM DETECTION  User:     Username: @DillyBubb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20334</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20338</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20339</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20340</th>\n",
       "      <td>ham</td>\n",
       "      <td>SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20343</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20344</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20345</th>\n",
       "      <td>ham</td>\n",
       "      <td>/ban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type                                               text\n",
       "20329       ham  SPAM DETECTION  User:     Username: @DillyBubb...\n",
       "20330       ham  SPAM DETECTION  User:     Username: @DillyBubb...\n",
       "20331       ham  SPAM DETECTION  User:     Username: @DillyBubb...\n",
       "20332       ham  SPAM DETECTION  User:     Username: @DillyBubb...\n",
       "20334       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20335       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20336       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20337       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20338       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20339       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20340       ham  SPAM ALERT  ðŸš”  User:     Username: @DillyBubbl...\n",
       "20343       ham                                               /ban\n",
       "20344       ham                                               /ban\n",
       "20345       ham                                               /ban"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
